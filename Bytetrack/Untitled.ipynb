{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ae6f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "#! pip install mpmath\n",
    "from mpmath import *\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime as dt\n",
    "import json \n",
    "import copy\n",
    "#!pip install opencv-python\n",
    "import cv2\n",
    "POWERFULNESS=2\n",
    "Home_folder=  \"/home/sophie/HMM-Tracking/Bytetrack\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8222c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tracking/Bytetrack/videos/GR77_20200512_111314_with_atq_tracking_with_HMM_resut.json\"):\n",
    "confidence_threshold = 0.2\n",
    "confidence_on_hmm_choice=2#1.5\n",
    "\"\"\"_summary_\n",
    "parameter: confidence_threshold\n",
    "\n",
    "Returns:\n",
    "    write a video with ATQ and put the results in the file /home/sophie/HMM-Tracking/Bytetrack/videos/GR77_20200512_111314_with_atq_tracking_with_HMM_resut.json\n",
    "\"\"\"\n",
    "track_with_observation=False\n",
    "nbr_visit=\"\"\n",
    "json_save_path=\"/home/sophie/HMM-Tracking/Bytetrack/videos/GR77_20200512_111314_with_atq_tracking_with_HMM_resut.json\"\n",
    "import numpy as np \n",
    "def softmax(x):\n",
    "    #return x/sum(x)\n",
    "    #return np.exp(x)/sum(np.exp(x))\n",
    "    return np.power(x,confidence_on_hmm_choice) / np.sum(np.power(x,confidence_on_hmm_choice), axis=0)\n",
    "\n",
    "def hungarian_choice(matrice,  value_of_confidence_on_track=1):\n",
    "    row_ind, col_ind = linear_sum_assignment(-matrice)\n",
    "    for idx,row in enumerate(row_ind):\n",
    "        matrice[row, col_ind[idx]] = value_of_confidence_on_track\n",
    "    return matrice\n",
    "\n",
    "def forward(V=np.array([0,1]), a={\"t=1\":np.array([[0.5,0.5]]) }, b={\"t=0\":np.array([0.5]),\"t=1\":np.array([0.5,0.5])}, initial_distribution=np.array([0.5]), T=1 ): #V=np.array([0,1]), a={\"t=1\":np.array([[0.5,0.5],[0.5,0.5]]) }, b={\"t=0\":np.array([0.5,0.5]),\"t=1\":np.array([0.5,0.5])}, initial_distribution=np.array([0.5,0.5])):\n",
    "    alpha = {}\n",
    "    alpha[V[1]] = initial_distribution * b[\"t=\"+str(V[1])]\n",
    "    for t in range(2, V.shape[0]):\n",
    "        tmp_alpha = alpha[V[t - 1]]\n",
    "        if \"t=\"+str(V[t]) in list(b.keys()) and (b[\"t=\"+str(V[t])].max()==b[\"t=\"+str(V[t])].min()) and (alpha[V[t-1]].max()== alpha[V[t-1]].min()) :\n",
    "            alpha[V[t]]=np.ones(a[\"t=\"+str(V[t])].shape[1]) #ca gère uniquement la première frame, il faudrait trouver un moyen de conserver les valeurs de alpha quand on a rien à la mangeoire\n",
    "        else:\n",
    "            tmp_b=b[\"t=\"+str(V[t])]\n",
    "            if \"t=\"+str(V[t]) in list(b.keys()) and  (b[\"t=\"+str(V[t])].max()==b[\"t=\"+str(V[t])].min()) and (alpha[V[t-1]].max()!= alpha[V[t-1]].min()):\n",
    "                tmp_alpha = np.power(alpha[V[t-1]],POWERFULNESS)  #np.exp(alpha[V[t-1]])\n",
    "\n",
    "            if \"t=\"+str(V[t]) in list(b.keys()) and  b[\"t=\"+str(V[t])].max()!=  b[\"t=\"+str(V[t])].min() :\n",
    "                #si on a une observation on ramène le compteur de beta à 0 avec 1 partout à la qui suivais frame\n",
    "                ##print(\"*****we rely on tracking only\")\n",
    "                tmp_alpha= np.ones(alpha[V[t-1]].shape)\n",
    "\n",
    "            alpha[V[t]]=np.zeros(a[\"t=\"+str(V[t])].shape[1])\n",
    "            for j in range(a[\"t=\"+str(V[t])].shape[1]):\n",
    "                alpha[V[t]][j] = tmp_alpha.dot(a[\"t=\"+str(V[t])][:, j]) *(b[\"t=\"+str(V[t])][j])\n",
    "            final_alpha_t=alpha[V[t]]\n",
    "\n",
    "        ##print(\"*****\",V[t], alpha[V[t]])\n",
    "        if alpha[V[t]].sum()!=0:\n",
    "            alpha[V[t]]=softmax(alpha[V[t]])\n",
    "\n",
    "    return alpha\n",
    "\n",
    "def backward(V=np.array([0,1]), a={\"t=1\":np.array([[0.5,0.5]]) }, b={\"t=0\":np.array([0.5]),\"t=1\":np.array([0.5,0.5])},  initial_distribution=np.array([0.5]), T=1):\n",
    "    beta = {}\n",
    "    # setting beta(T) = 1\n",
    "    beta[V[-1]] = np.ones((a[\"t=\"+str(V[-1])].shape[1]))\n",
    "\n",
    "    # Loop in backward way from T-1 to\n",
    "    # Due to python indexing the actual loop will be T-2 to 0\n",
    "    for t in range(V.shape[0] - 2, -1, -1):\n",
    "        #tmp_beta=beta[V[t+1]]\n",
    "        #if \"t=\"+str(V[t]) in list(b.keys()) and (b[\"t=\"+str(V[t])].max()==  b[\"t=\"+str(V[t])].min()) and  ( beta[V[t+1]].max()== beta[V[t+1]].min()):\n",
    "        \"\"\" ca c'est lorsqu'on a pas d'observation, et que l'on vient de commencer avec beta, on préfère \n",
    "        laisser beta t1+1 à 1 et ne pas se laisser influencer par les probabilités de bytetrack\n",
    "        ??? mais je ne suis pas sure que ca influence par ce que a est normaliser à 1 comme somme de cells par ligne??? à veirifier et tester \"\"\"\n",
    "        #  a_temp=np.ones(a[\"t=\"+str(V[t+1])].shape)\n",
    "        #beta[V[t]]=beta[V[t+1]]\n",
    "        #  beta[V[t]]=np.zeros(a[\"t=\"+str(V[t+1])].shape[0])\n",
    "        #  for j in range(a[\"t=\"+str(V[t+1])].shape[0]):\n",
    "        #    beta[V[t]][j] = (tmp_beta * b[\"t=\"+str(V[t + 1])]).dot(a_temp[j, :])\n",
    "        #else:\n",
    "        if \"t=\"+str(V[t]) in list(b.keys()):\n",
    "            tmp_beta=beta[V[t+1]]\n",
    "            if  (b[\"t=\"+str(V[t+1])].max()==b[\"t=\"+str(V[t+1])].min()) and (beta[V[t+1]].max()== beta[V[t+1]].min()) :\n",
    "                beta[V[t]]=np.ones(a[\"t=\"+str(V[t+1])].shape[0]) #ca gère uniquement la première frame, il faudrait trouver un moyen de conserver les valeurs de alpha quand on a rien à la mangeoire\n",
    "            else:\n",
    "                tmp_b=b[\"t=\"+str(V[t])]\n",
    "                if  (b[\"t=\"+str(V[t+1])].max()==b[\"t=\"+str(V[t+1])].min()) and (beta[V[t+1]].max()!= beta[V[t+1]].min()):\n",
    "                    tmp_beta = np.power(beta[V[t+1]],POWERFULNESS)  #np.exp(alpha[V[t-1]])\n",
    "\n",
    "                if  b[\"t=\"+str(V[t+1])].max()!=  b[\"t=\"+str(V[t+1])].min() :\n",
    "                    #si on a une observation on ramène le compteur de beta à 0 avec 1 partout à la qui suivais frame\n",
    "                    ##print(\"*****we rely on tracking only\", b[\"t=\"+str(V[t + 1])], tmp_beta * b[\"t=\"+str(V[t + 1])] )\n",
    "                    tmp_beta= np.ones(beta[V[t+1]].shape)\n",
    "\n",
    "                beta[V[t]]=np.zeros(a[\"t=\"+str(V[t+1])].shape[0])\n",
    "                for j in range(a[\"t=\"+str(V[t+1])].shape[0]):\n",
    "                    beta[V[t]][j] = (tmp_beta * b[\"t=\"+str(V[t + 1])]).dot(a[\"t=\"+str(V[t+1])][j, :])\n",
    "            if beta[V[t]].sum()!=0:\n",
    "                beta[V[t]]=softmax(beta[V[t]])\n",
    "            ##print(\"*****\",V[t], beta[V[t]])\n",
    "\n",
    "        \"\"\"if \"t=\"+str(V[t]) in list(b.keys()) :#and  b[\"t=\"+str(V[t])].max()!=  b[\"t=\"+str(V[t])].min():\n",
    "            #si on a une observation on ramène le compteur de beta à 0 avec 1 partout à la qui suivais frame\n",
    "            #tmp_beta= np.ones(beta[V[t+1]].shape)\n",
    "            tmp_beta=beta[V[t+1]]\n",
    "            beta[V[t]]=np.zeros(a[\"t=\"+str(V[t+1])].shape[0])\n",
    "            for j in range(a[\"t=\"+str(V[t+1])].shape[0]):\n",
    "                beta[V[t]][j] = (tmp_beta * b[\"t=\"+str(V[t + 1])]).dot(a[\"t=\"+str(V[t+1])][j, :])\n",
    "\n",
    "            beta[V[t]]=softmax(beta[V[t]])#sophie mod  beta[V[t]]/beta[V[t]].sum() #\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    return beta\n",
    "\n",
    "\n",
    "\n",
    "def forward_backward_L(V=np.array([0,1]), a={\"t=1\":np.array([[0.5,0.25]]) }, b={\"t=0\":np.array([0.5]),\"t=1\":np.array([0.5,0.5])}, initial_distribution=np.array([0.5]), T=1 ): #V=np.array([0,1]), a={\"t=1\":np.array([[0.5,0.5],[0.5,0.5]]) }, b={\"t=0\":np.array([0.5,0.5]),\"t=1\":np.array([0.5,0.5])}, initial_distribution=np.array([0.5,0.5])):):\n",
    "    beta = backward(V,a,b,initial_distribution,T)\n",
    "    alpha = forward(V,a,b,initial_distribution,T)\n",
    "    L={}\n",
    "    for t in V[1:]:\n",
    "        #if t==400:\n",
    "        #  #print(alpha[t],\"***\",beta[t])\n",
    "        L[\"t=\"+str(t)]=alpha[t]*beta[t]\n",
    "        if L[\"t=\"+str(t)].sum()!=0:\n",
    "            L[\"t=\"+str(t)]=L[\"t=\"+str(t)]/L[\"t=\"+str(t)].sum()\n",
    "\n",
    "    ##print(\"final t\", t)\n",
    "\n",
    "    return L,beta,alpha\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(track_with_observation) as f:\n",
    "    data = json.load(f)\n",
    "max_frame=max([int(i) for i in list(data.keys())])\n",
    "\n",
    "#### on crée la list des identités et ajoutons des noms au format identity'numéros' pour les inconus \n",
    "identities=set()\n",
    "for frame, value in data.items():\n",
    "    for key in value[\"observation\"].keys():\n",
    "        # if 'observed' in value.keys():\n",
    "        identities.add(key)\n",
    "while len(identities)<15:\n",
    "    identities.add(\"identities\"+str(len(identities)))\n",
    "\n",
    "\n",
    "\n",
    "V=[0]\n",
    "a={}\n",
    "b={}\n",
    "for identity in identities:\n",
    "    b[str(identity)]={}\n",
    "initial_distribution = np.array([1/len(data[\"0\"][\"current\"]) for i in data[\"0\"][\"current\"] ])\n",
    "for frame_id, value in data.items():\n",
    "    if  frame_id!=\"0\" and int(frame_id)<max_frame: #int(frame)>100: #(frame!=\"0\" and int(frame)%25==0) or\n",
    "        a[\"t=\"+frame_id]=np.array(value[\"matrice\"]) ######### without the hungarian choice hungarian_choice(np.array(value[\"matrice\"]))\n",
    "\n",
    "        for identity in identities:\n",
    "            b[str(identity)][\"t=\"+frame_id]=np.array([1 for i in value[\"matrice\"][1] ])\n",
    "\n",
    "        for key in list(value[\"observation\"]):\n",
    "            b[str(key)][\"t=\"+frame_id]=np.array(value[\"observation\"][key] )\n",
    "            #if b[str(key)][\"t=\"+frame_id].max()>0.1:\n",
    "            #    #print(\"observation at frame\", frame_id, key)\n",
    "\n",
    "        #if 'observed' in list(value.keys()):\n",
    "        #  b[str(value[\"observed\"])][\"t=\"+frame_id]=np.array(value[\"observation\"])\n",
    "        #quand l'animal n'est pas observé ca pourrait être un 1- la d istance à voir mais ca a des conséquence, l'ideal aurait été d'^tre sure quant à celui qui est à la mangeoire\n",
    "        V.append(int(frame_id))\n",
    "\n",
    "\n",
    "V=V[:-1]#3000]#-1]\n",
    "V=np.array(V)\n",
    "T=len(V)-2\n",
    "L={}\n",
    "Beta={}\n",
    "Alpha={}\n",
    "\n",
    "\n",
    "for identity in list(identities) [:15]:\n",
    "    if True:#identity=='4809.0':\n",
    "        L[identity], Beta[identity], Alpha[identity]= forward_backward_L(V=V,  a=a, b=b[str(identity)], initial_distribution=initial_distribution, T=V[-1] )\n",
    "        #print(identity, \"process finished\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################Adding ATQ from the HMM #########################\n",
    "#Atq are added by considering the animal on which the confidence on an identity was greater than confidence_threshold\n",
    "\n",
    "\n",
    "for t in V[1:] : \n",
    "    matrice=np.zeros((len(L[list(identities)[0]][\"t=\"+str(t)]),len(list(identities))))\n",
    "    for idx,identity in enumerate(list(identities)[:15]):\n",
    "        matrice[:,idx]= L[identity][\"t=\"+str(t)]\n",
    "    #hungarian fin the correspondance with the minimal cost, since we want to maximize the  sum  of probabilities,  we will use -probability  \n",
    "    \"\"\"matrice_df={}\n",
    "    for identity in identities:\n",
    "            matrice_df[identity]= L[identity][\"t=\"+str(t)]\n",
    "    matrice_df=pd.DataFrame(matrice_df)\"\"\"\n",
    "\n",
    "    #######Hungarian version whICH seems to be ok   \n",
    "    try:\n",
    "        row_ind, col_ind = linear_sum_assignment(-matrice) #since the function is looking for the assignement minimizing the sum, we put the opposite of the propabiliy in cells \n",
    "    except:\n",
    "        print(\"xeption on this matrix\")#,t,list(identities)[3], L[list(identities)[3]][\"t=\"+str(t)], matrice)            \n",
    "    for idx, row in enumerate(row_ind):\n",
    "      data[str(t)][\"current\"][idx][\"atq\"] = list(identities)[col_ind[idx]]\n",
    "\n",
    "\n",
    "    ##########version with the maximum one feeting \n",
    "    \"\"\"for idx, track in enumerate(data[str(t)][\"current\"]):\n",
    "        track[\"atq\"] = \"None\"\n",
    "        identity_with_max_val= np.argmax(matrice[idx])\n",
    "        #print(identity_with_max_val, list(identities)[identity_with_max_val])\n",
    "        if  L[list(identities)[identity_with_max_val]][\"t=\"+str(t)][idx]>confidence_threshold:\n",
    "            data[str(t)][\"current\"][idx][\"atq\"] = list(identities)[identity_with_max_val]\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################\n",
    "#This smoothing will not be used \n",
    "\n",
    "\n",
    "def get_track_from_id_and_time(track_id,t):\n",
    "    for idx, track in enumerate(data[str(t)][\"current\"]):\n",
    "            if track[\"track_id\"]==track_id:\n",
    "                return track\n",
    "\n",
    "\n",
    "\n",
    "def smooting_from_past(data, gap=750):\n",
    "    for t in V[1:] : \n",
    "        for idx, track in enumerate(data[str(t)][\"current\"]):\n",
    "                if track[\"atq\"]==\"None\":\n",
    "                    track_id=track[\"track_id\"]\n",
    "                    track[\"atq_from_previous\"]=\"None\"\n",
    "                    if t>gap:\n",
    "                        track_previous = get_track_from_id_and_time(track_id,t-1)\n",
    "                        track_far_previous = get_track_from_id_and_time(track_id,t-gap)\n",
    "                        if track_previous!=None and track_far_previous!=None:\n",
    "                            if track_previous[\"atq_from_previous\"]!=\"None\" and track_far_previous[\"atq_from_previous\"]!=\"None\":\n",
    "                                if track_previous[\"atq_from_previous\"]== track_far_previous[\"atq_from_previous\"]:\n",
    "                                    #print(t)\n",
    "                                    #print(track)\n",
    "                                    data[str(t)][\"current\"][idx][\"atq_from_previous\"]= track_previous[\"atq_from_previous\"]\n",
    "                                    ##print(track)\n",
    "                        #except(e):\n",
    "                    #    #print(\"an exception occur this is its description:\",e)\n",
    "                else:\n",
    "                    data[str(t)][\"current\"][idx][\"atq_from_previous\"]= track[\"atq\"]\n",
    "\n",
    "\n",
    "def smooting_from_future(data, gap=750):\n",
    "    for t in reversed(V[1:]) : \n",
    "        for idx, track in enumerate(data[str(t)][\"current\"]):\n",
    "                if track[\"atq\"]==\"None\":\n",
    "                    track_id=track[\"track_id\"]\n",
    "                    track[\"atq_from_future\"]=\"None\"\n",
    "                    if V[-1]-t>gap:\n",
    "                        track_future = get_track_from_id_and_time(track_id,t+1)\n",
    "                        track_far_future = get_track_from_id_and_time(track_id,t+gap)\n",
    "\n",
    "                        if track_future!=None and track_far_future!=None:\n",
    "\n",
    "                            if track_future[\"atq_from_future\"]!=\"None\" and track_far_future[\"atq_from_future\"]!=\"None\":\n",
    "\n",
    "                                if track_future[\"atq_from_future\"]== track_far_future[\"atq_from_future\"]:\n",
    "                                    #print(t)\n",
    "\n",
    "                                    data[str(t)][\"current\"][idx][\"atq_from_future\"]= track_future[\"atq_from_future\"]\n",
    "                                    #print( data[str(t)][\"current\"][idx])\n",
    "                                    ##print(track)\n",
    "                        #except(e):\n",
    "                    #    #print(\"an exception occur this is its description:\",e)\n",
    "                else:\n",
    "                    data[str(t)][\"current\"][idx][\"atq_from_future\"]= track[\"atq\"]\n",
    "\n",
    "smooting_from_future(data,gap=1000)#float('inf')) #=1000)#   4à secondes de gap\n",
    "smooting_from_past(data,gap=1000)#float('inf')) # 1000)#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################## Adding ATQ to the json file and the video \n",
    "\n",
    "\n",
    "##############writting on the video#########################\n",
    "\n",
    "\n",
    "##print(tracks_with_atq)\n",
    "video_path=Home_folder+\"/videos/GR77_20200512_111314.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "save_path= Home_folder+\"/videos/GR77_20200512_111314_with_atq\"+str(nbr_visit)+\".mp4\"\n",
    "vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (int(width), int(height)))     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Center coordinates\n",
    "center_coordinates = (625, 70)\n",
    "\n",
    "# Radius of circle\n",
    "radius = 2\n",
    "\n",
    "# Blue color in BGR\n",
    "color = (255, 0, 0)\n",
    "\n",
    "# Line thickness of 2 px\n",
    "thickness = 2\n",
    "\n",
    "# Using cv2.circle() method\n",
    "# Draw a circle with blue line borders of thickness of 2 px\n",
    "#frame = cv2.circle(frame, center_coordinates, radius, color, thickness)\n",
    "\n",
    "\n",
    "#cv2.imwrite(\"image_.jpg\", frame) \n",
    "\n",
    "#print(\"********************** we start writting in the video\")\n",
    "track_file=Home_folder+\"/videos/GR77_20200512_111314tracking_resut.json\"\n",
    "with open(track_file) as f:\n",
    "        tracks = json.load(f) \n",
    "\n",
    "\n",
    "ret_val, frame = cap.read()\n",
    "frame_id=1\n",
    "tracking_result={}\n",
    "while ret_val and frame_id!=V[-1]: \n",
    "    dct={}\n",
    "    ret_val, frame = cap.read()\n",
    "    frame = cv2.circle(frame, center_coordinates, radius, color, thickness)\n",
    "    if str(frame_id) in data.keys():\n",
    "        if (frame!=\"0\" ):\n",
    "            cv2.putText(frame, str(frame_id),(90+580, 20),0, 5e-3 * 200, (0,255,0),2)\n",
    "            for track in data[str(frame_id)][\"current\"]:\n",
    "                track_id=track[\"track_id\"] \n",
    "                tlwh = track[\"location\"]\n",
    "                ##print(track)\n",
    "                atq= track[\"atq\"] \n",
    "                if atq==\"None\" and \"atq_from_previous\" in track.keys() :\n",
    "                    if track[\"atq_from_previous\"]!=\"None\":\n",
    "                        atq= track[\"atq_from_previous\"]+'fp'\n",
    "                    elif track[\"atq_from_future\"]!=\"None\":\n",
    "                        atq= track[\"atq_from_future\"]+'ff'\n",
    "\n",
    "                tid= str(track_id)+\", atq:\"+str(atq)\n",
    "                ##print(tid)\n",
    "                if atq!=\"None\":\n",
    "                    dct[atq]=(int(tlwh[0]), int(tlwh[1]), int(tlwh[2]), int(tlwh[3]) )\n",
    "                    ##print(\"we create the dct\")\n",
    "                cv2.rectangle(frame, (int(tlwh[0]), int(tlwh[1])), (int(tlwh[0])+int(tlwh[2]), int(tlwh[1])+int(tlwh[3])) ,(255,255,255), 2)\n",
    "                cv2.rectangle(frame, (580, 20), (90+580, 115+20) ,(255,255,255), 2)\n",
    "\n",
    "                cv2.putText(frame, str(tid),(int(tlwh[0]), int(tlwh[1])),0, 5e-3 * 200, (0,255,0),2)\n",
    "\n",
    "            tracking_result[frame_id]=dct\n",
    "            vid_writer.write(frame)\n",
    "    #print(\"\\n\", \"\\n\")\n",
    "    frame_id=frame_id+1\n",
    "with open(json_save_path, 'w') as outfile:\n",
    "    json.dump(tracking_result, outfile)\n",
    "vid_writer.release()\n",
    "#plutôt la surface d'intersection des rectangles plutôt que la distance eucledienne \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
