{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb2a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ce qu'on veut faire: \n",
    "- faire un hungarian avec les L retournés par le module de tracking couplé au  HMM \n",
    "\n",
    "Liste des pbs du codes:\n",
    "- le 4809 génère des nan certainement du au moment où il y'a des detections qui disparaissent ??? \n",
    "-du genre on passe de 15 animaux à 14 à investiguer en detail\n",
    "\n",
    "\n",
    "\n",
    "possible good news to check:\n",
    "- un switch d'identité serait réglé par le hmm sur le 4809 à la 1761 seconde \n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7198a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "#! pip install mpmath\n",
    "from mpmath import *\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import datetime as dt\n",
    "import json \n",
    "import copy\n",
    "import numpy as np \n",
    "import cv2\n",
    "\n",
    "POWERFULNESS=2\n",
    "Home_folder=  \"/home/sophie/HMM-Tracking/Bytetrack\"\n",
    "confidence_on_hmm_choice=1.5\n",
    "confidence_threshold = 0.2\n",
    "\n",
    "#en supposant que les observations sont independantes la normalisation à 1 des alpha et beta est acceptable \n",
    "#la solution qui suivra sera de choisir l'identité la plus acceptée au niveau de L et de l'affecté à la localisation identifié dans le tracking \n",
    "\n",
    "def softmax(x):\n",
    "    #return x/sum(x)\n",
    "    #return np.exp(x)/sum(np.exp(x))\n",
    "    return np.power(x,confidence_on_hmm_choice) / np.sum(np.power(x,confidence_on_hmm_choice), axis=0)\n",
    "\n",
    "def hungarian_choice(matrice, value_of_confidence_on_track=1):\n",
    "        row_ind, col_ind = linear_sum_assignment(-matrice)\n",
    "        for idx,row in enumerate(row_ind):\n",
    "            matrice[row, col_ind[idx]] = value_of_confidence_on_track\n",
    "        return matrice\n",
    "\n",
    "def forward(V=np.array([0,1]), a={\"t=1\":np.array([[0.5,0.5]]) }, b={\"t=0\":np.array([0.5]),\"t=1\":np.array([0.5,0.5])}, initial_distribution=np.array([0.5]), T=1 ): #V=np.array([0,1]), a={\"t=1\":np.array([[0.5,0.5],[0.5,0.5]]) }, b={\"t=0\":np.array([0.5,0.5]),\"t=1\":np.array([0.5,0.5])}, initial_distribution=np.array([0.5,0.5])):\n",
    "    alpha = {}\n",
    "    alpha[V[1]] = initial_distribution * b[\"t=\"+str(V[1])]\n",
    "    for t in range(2, V.shape[0]):\n",
    "        tmp_alpha = alpha[V[t - 1]]\n",
    "        \n",
    "        if \"t=\"+str(V[t]) in list(b.keys()) and (b[\"t=\"+str(V[t])].max()==b[\"t=\"+str(V[t])].min()) and (alpha[V[t-1]].max()== alpha[V[t-1]].min()) :\n",
    "            #si on a pas d'observation et pas d'observation et un alpha qui est egalitaire, ca ne sert à rien de donner de la force au track auquel letracker est plus confident \n",
    "            alpha[V[t]]=np.ones(a[\"t=\"+str(V[t])].shape[1]) #ca gère uniquement la première frame, il faudrait trouver un moyen de conserver les valeurs de alpha quand on a rien à la mangeoire\n",
    "            #print(t,\"b=1, alph=1\")\n",
    "        else:\n",
    "            tmp_b=b[\"t=\"+str(V[t])]\n",
    "            if \"t=\"+str(V[t]) in list(b.keys()) and  (b[\"t=\"+str(V[t])].max()==b[\"t=\"+str(V[t])].min()) and (alpha[V[t-1]].max()!= alpha[V[t-1]].min()):\n",
    "                #si on a pas d'observation mais qu'on a une valeur de alpha informative, on lui donne plus de poids pour en donner moins aux confidences du tracker pour eviter que les tracks les plus certains prennent une grande probabilité sur l'identité\n",
    "                tmp_alpha = np.power(alpha[V[t-1]],POWERFULNESS)  #np.exp(alpha[V[t-1]])\n",
    "                #print(\"we leave\")\n",
    "                #print(t,\"b=1, alph#1\")\n",
    "\n",
    "            if \"t=\"+str(V[t]) in list(b.keys()) and  b[\"t=\"+str(V[t])].max()!=  b[\"t=\"+str(V[t])].min() :\n",
    "                #si on a une observation on ramène le compteur de beta à 0 avec 1 partout à la qui suivais frame\n",
    "                tmp_alpha= np.ones(alpha[V[t-1]].shape)\n",
    "                #print(t,\"b#1, \")\n",
    "                \n",
    "                \"\"\"alpha[V[t]]=np.zeros(a[\"t=\"+str(V[t])].shape[1])\n",
    "                for j in range(a[\"t=\"+str(V[t])].shape[1]):\n",
    "                    alpha[V[t]][j] = tmp_alpha.dot(a[\"t=\"+str(V[t])][:, j]) *(b[\"t=\"+str(V[t])][j])\n",
    "                final_alpha_t=alpha[V[t]]\n",
    "                print(b[\"t=\"+str(V[t])] ,\"******\", a[\"t=\"+str(V[t])] )\"\"\"\n",
    "\n",
    "            alpha[V[t]]=np.zeros(a[\"t=\"+str(V[t])].shape[1])\n",
    "            for j in range(a[\"t=\"+str(V[t])].shape[1]):\n",
    "                alpha[V[t]][j] = tmp_alpha.dot(a[\"t=\"+str(V[t])][:, j]) *(b[\"t=\"+str(V[t])][j])\n",
    "            final_alpha_t=alpha[V[t]]\n",
    "\n",
    "        ##print(\"*****\",V[t], alpha[V[t]])\n",
    "        if alpha[V[t]].sum()!=0:\n",
    "            alpha[V[t]]=softmax(alpha[V[t]])\n",
    "            \n",
    "        #if t==10198:# or t==281:\n",
    "        #    print(\"******************************************************\")\n",
    "        #    print(\"*****alpha t-1\", tmp_alpha,\"*****a\", a[\"t=\"+str(V[t])].shape,\"****b\", b[\"t=\"+str(V[t])] ,\"****alpha\",alpha[V[t]] ,\"\\n\")\n",
    "        \n",
    "            \n",
    "    return alpha\n",
    "\n",
    "def backward(V=np.array([0,1]), a={\"t=1\":np.array([[0.5,0.5]]) }, b={\"t=0\":np.array([0.5]),\"t=1\":np.array([0.5,0.5])},  initial_distribution=np.array([0.5]), T=1):\n",
    "    beta = {}\n",
    "    # setting beta(T) = 1\n",
    "    beta[V[-1]] = np.ones((a[\"t=\"+str(V[-1])].shape[1]))\n",
    "\n",
    "    # Loop in backward way from T-1 to\n",
    "    # Due to python indexing the actual loop will be T-2 to 0\n",
    "    for t in range(V.shape[0] - 2, -1, -1):\n",
    "        #tmp_beta=beta[V[t+1]]\n",
    "        #if \"t=\"+str(V[t]) in list(b.keys()) and (b[\"t=\"+str(V[t])].max()==  b[\"t=\"+str(V[t])].min()) and  ( beta[V[t+1]].max()== beta[V[t+1]].min()):\n",
    "        \"\"\" ca c'est lorsqu'on a pas d'observation, et que l'on vient de commencer avec beta, on préfère \n",
    "        laisser beta t1+1 à 1 et ne pas se laisser influencer par les probabilités de bytetrack\n",
    "        ??? mais je ne suis pas sure que ca influence par ce que a est normaliser à 1 comme somme de cells par ligne??? à veirifier et tester \"\"\"\n",
    "        #  a_temp=np.ones(a[\"t=\"+str(V[t+1])].shape)\n",
    "        #beta[V[t]]=beta[V[t+1]]\n",
    "        #  beta[V[t]]=np.zeros(a[\"t=\"+str(V[t+1])].shape[0])\n",
    "        #  for j in range(a[\"t=\"+str(V[t+1])].shape[0]):\n",
    "        #    beta[V[t]][j] = (tmp_beta * b[\"t=\"+str(V[t + 1])]).dot(a_temp[j, :])\n",
    "        #else:\n",
    "        if \"t=\"+str(V[t]) in list(b.keys()):\n",
    "            tmp_beta=beta[V[t+1]]\n",
    "            if \"t=\"+str(V[t]) in list(b.keys()) and (b[\"t=\"+str(V[t+1])].max()==b[\"t=\"+str(V[t+1])].min()) and (beta[V[t+1]].max()== beta[V[t+1]].min()) :\n",
    "                beta[V[t]]=np.ones(a[\"t=\"+str(V[t+1])].shape[0]) #ca gère uniquement la première frame, il faudrait trouver un moyen de conserver les valeurs de alpha quand on a rien à la mangeoire\n",
    "            else:\n",
    "                tmp_b=b[\"t=\"+str(V[t])]\n",
    "                if \"t=\"+str(V[t]) in list(b.keys()) and  (b[\"t=\"+str(V[t+1])].max()==b[\"t=\"+str(V[t+1])].min()) and (beta[V[t+1]].max()!= beta[V[t+1]].min()):\n",
    "                    tmp_beta = np.power(beta[V[t+1]],POWERFULNESS)  #np.exp(alpha[V[t-1]])\n",
    "\n",
    "                if \"t=\"+str(V[t]) in list(b.keys()) and  b[\"t=\"+str(V[t+1])].max()!=  b[\"t=\"+str(V[t+1])].min() :\n",
    "                    #si on a une observation on ramène le compteur de beta à 0 avec 1 partout à la qui suivais frame\n",
    "                    ##print(\"*****we rely on tracking only\", b[\"t=\"+str(V[t + 1])], tmp_beta * b[\"t=\"+str(V[t + 1])] )\n",
    "                    tmp_beta= np.ones(beta[V[t+1]].shape)\n",
    "\n",
    "                beta[V[t]]=np.zeros(a[\"t=\"+str(V[t+1])].shape[0])\n",
    "                for j in range(a[\"t=\"+str(V[t+1])].shape[0]):\n",
    "                    beta[V[t]][j] = (tmp_beta * b[\"t=\"+str(V[t + 1])]).dot(a[\"t=\"+str(V[t+1])][j, :])\n",
    "            if beta[V[t]].sum()!=0:\n",
    "                beta[V[t]]=softmax(beta[V[t]])\n",
    "            ##print(\"*****\",V[t], beta[V[t]])\n",
    "\n",
    "        #if t==10198:# or t==281:\n",
    "        #    print(\"******************************************************\")\n",
    "        #    print(\"*****beta t+1\",beta[V[t]].shape)# tmp_beta,\"*****b\", a[\"t=\"+str(V[t])].shape,\"****b\", b[\"t=\"+str(V[t])] ,\"****beta\",beta[V[t]] ,\"\\n\")\n",
    "       \n",
    "        \"\"\"if \"t=\"+str(V[t]) in list(b.keys()) :#and  b[\"t=\"+str(V[t])].max()!=  b[\"t=\"+str(V[t])].min():\n",
    "            #si on a une observation on ramène le compteur de beta à 0 avec 1 partout à la qui suivais frame\n",
    "            #tmp_beta= np.ones(beta[V[t+1]].shape)\n",
    "            tmp_beta=beta[V[t+1]]\n",
    "            beta[V[t]]=np.zeros(a[\"t=\"+str(V[t+1])].shape[0])\n",
    "            for j in range(a[\"t=\"+str(V[t+1])].shape[0]):\n",
    "                beta[V[t]][j] = (tmp_beta * b[\"t=\"+str(V[t + 1])]).dot(a[\"t=\"+str(V[t+1])][j, :])\n",
    "\n",
    "            beta[V[t]]=softmax(beta[V[t]])#sophie mod  beta[V[t]]/beta[V[t]].sum() #\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    return beta\n",
    "\n",
    " \n",
    "def forward_backward_L(V=np.array([0,1]), a={\"t=1\":np.array([[0.5,0.25]]) }, b={\"t=0\":np.array([0.5]),\"t=1\":np.array([0.5,0.5])}, initial_distribution=np.array([0.5]), T=1 ): #V=np.array([0,1]), a={\"t=1\":np.array([[0.5,0.5],[0.5,0.5]]) }, b={\"t=0\":np.array([0.5,0.5]),\"t=1\":np.array([0.5,0.5])}, initial_distribution=np.array([0.5,0.5])):):\n",
    "    beta = backward(V,a,b,initial_distribution,T)\n",
    "    alpha = forward(V,a,b,initial_distribution,T)\n",
    "    L={}\n",
    "    for t in V[1:]:\n",
    "        #if t==10000:\n",
    "        #    print(alpha[t],\"***\",beta[t])\n",
    "        \n",
    "        L[\"t=\"+str(t)]=alpha[t]*beta[t]\n",
    "        if L[\"t=\"+str(t)].sum()!=0:\n",
    "          L[\"t=\"+str(t)]=L[\"t=\"+str(t)]/L[\"t=\"+str(t)].sum()\n",
    "\n",
    "        if t==1432:\n",
    "            print(\"Final**********\",t,L[\"t=\"+str(t)],alpha[t], beta[t])\n",
    "        #print(\"final t\", t)\n",
    "\n",
    "    return L,beta,alpha\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(Home_folder+'/videos/GR77_20200512_111314DBN_resut_with_observations_visits_62.json') as f:\n",
    "  data = json.load(f)\n",
    "max_frame=max([int(i) for i in list(data.keys())])\n",
    "\n",
    "#### on crée la list des identités et ajoutons des noms au format identity'numéros' pour les inconus \n",
    "identities=set()\n",
    "for frame, value in data.items():\n",
    "  for key in value[\"observation\"].keys():\n",
    "    # if 'observed' in value.keys():\n",
    "    identities.add(key)\n",
    "while len(identities)<15:\n",
    "  identities.add(\"identities\"+str(len(identities)))\n",
    "\n",
    "\n",
    "\n",
    "V=[0]\n",
    "a={}\n",
    "b={}\n",
    "for identity in identities:\n",
    "  b[str(identity)]={}\n",
    "initial_distribution = np.array([1/len(data[\"0\"][\"current\"]) for i in data[\"0\"][\"current\"] ])\n",
    "for frame_id, value in data.items():\n",
    "  if  frame_id!=\"0\" and int(frame_id)<max_frame: #int(frame)>100: #(frame!=\"0\" and int(frame)%25==0) or\n",
    "    a[\"t=\"+frame_id]=hungarian_choice(np.array(value[\"matrice\"]))\n",
    "\n",
    "    for identity in identities:\n",
    "      b[str(identity)][\"t=\"+frame_id]=np.array([1 for i in value[\"matrice\"][1] ])\n",
    "\n",
    "    for key in list(value[\"observation\"]):\n",
    "        b[str(key)][\"t=\"+frame_id]=np.array(value[\"observation\"][key] )\n",
    "        if b[str(key)][\"t=\"+frame_id].max()>0.1:\n",
    "            print(\"observation at frame\", frame_id, key)\n",
    "        \n",
    "    #if 'observed' in list(value.keys()):\n",
    "    #  b[str(value[\"observed\"])][\"t=\"+frame_id]=np.array(value[\"observation\"])\n",
    "    #quand l'animal n'est pas observé ca pourrait être un 1- la d istance à voir mais ca a des conséquence, l'ideal aurait été d'^tre sure quant à celui qui est à la mangeoire\n",
    "    V.append(int(frame_id))\n",
    "\n",
    "\n",
    "V=V[:-1]\n",
    "V=np.array(V)\n",
    "T=len(V)-2\n",
    "L={}\n",
    "Beta={}\n",
    "Alpha={}\n",
    "\n",
    "\n",
    "for identity in list(identities) [:15]:\n",
    "    if True:# identity=='4812.0':\n",
    "        L[identity], Beta[identity], Alpha[identity]= forward_backward_L(V=V,  a=a, b=b[str(identity)], initial_distribution=initial_distribution, T=V[-1] )\n",
    "        print(identity, \"process finished\")\n",
    "\n",
    "\n",
    "####This part for matching  atq identities to objects ###########\n",
    "import pandas as pd\n",
    "plot_alpha={}\n",
    "plot_beta={}\n",
    "plot_L=pd.DataFrame(columns=[i for i in range(16)])\n",
    "#print(plot)\n",
    "#on va observer 4808"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d312157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#!pip install plotly\n",
    "import plotly.express as px\n",
    "\n",
    "plot_alpha={}\n",
    "plot_beta={}\n",
    "plot_L={}\n",
    "for identity in identities:\n",
    "    plot_L[identity]=pd.DataFrame(columns=[i+1 for i in range(15)])\n",
    "    plot_alpha[identity]=pd.DataFrame(columns=[i+1 for i in range(15)])\n",
    "    plot_beta[identity]=pd.DataFrame(columns=[i+1 for i in range(15)])\n",
    "\n",
    "for t in V[1:] :\n",
    "    #print(t)\n",
    "    for identity in identities:\n",
    "        if identity=='4812.0':\n",
    "            plot_L[identity].loc[t]= [None for i in range(15)]\n",
    "            plot_alpha[identity].loc[t]= [None for i in range(15)]\n",
    "            plot_beta[identity].loc[t]= [None for i in range(15)]\n",
    "            for idx, track in enumerate(data[str(t)][\"current\"]) :\n",
    "                plot_L[identity].loc[t, track[\"track_id\"]]=L[identity][\"t=\"+str(t)][idx]\n",
    "                plot_alpha[identity].loc[t, track[\"track_id\"]]= Alpha[identity][t][idx]\n",
    "                #print(Alpha[identity][t][idx])\n",
    "                plot_beta[identity].loc[t, track[\"track_id\"]]=Beta[identity][t][idx]\n",
    "               \n",
    "                \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "plot_L[\"4812.0\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for identity in identities:\n",
    "    if identity in identities:#[\"4808.0\"]:\n",
    "        plot_L[identity][\"index\"]=plot_L[identity].index\n",
    "        plot_alpha[identity][\"index\"]=plot_alpha[identity].index\n",
    "        plot_beta[identity][\"index\"]=plot_beta[identity].index\n",
    "        \n",
    "        fig_alpha = px.line(plot_alpha[identity], x=\"index\", y=plot_alpha[identity].columns, title=\"alpha for \"+str(identity))\n",
    "        fig_beta = px.line(plot_beta[identity], x=\"index\", y=plot_alpha[identity].columns, title=\"beta for \"+str(identity))\n",
    "        fig_L = px.line(plot_L[identity], x=\"index\", y=plot_alpha[identity].columns, title=\"L for \"+str(identity))\n",
    "        \"\"\"fig_L = px.line(plot_L[identity], x=\"index\", y=plot_L[identity].columns, title=\"L for \"+str(identity))\n",
    "        fig_alpha = px.line(plot_alpha[identity], x=\"index\", y=plot_alpha[identity].columns, title=\"alpha for \"+str(identity))\n",
    "        fig_beta = px.line(plot_beta[identity], x=\"index\", y=plot_beta[identity].columns, title=\"beta for \"+str(identity))\n",
    "        \"\"\"\n",
    "        fig_L.show()\n",
    "        fig_alpha.show()\n",
    "        fig_beta.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894798e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107abb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(identities))\n",
    "for t in V[1:] : \n",
    "        matrice=np.zeros((len(L[list(identities)[0]][\"t=\"+str(t)]),len(list(identities))))\n",
    "        for idx,identity in enumerate(list(identities)[:15]):\n",
    "            matrice[:,idx]= L[identity][\"t=\"+str(t)]\n",
    "        #hungarian fin the correspondance with the minimal cost, since we want to maximize the  sum  of probabilities,  we will use -probability  \n",
    "        \"\"\"matrice_df={}\n",
    "        for identity in identities:\n",
    "                matrice_df[identity]= L[identity][\"t=\"+str(t)]\n",
    "        matrice_df=pd.DataFrame(matrice_df)\"\"\"\n",
    "\n",
    "        #######Hungarian version who seems to be ok   \n",
    "        #try:\n",
    "        #    row_ind, col_ind = linear_sum_assignment(-matrice) #since the function is looking for the assignement minimizing the sum, we put the opposite of the propabiliy in cells \n",
    "        #except:\n",
    "        #    print(\"xeption on this matrix\")#,t,list(identities)[3], L[list(identities)[3]][\"t=\"+str(t)], matrice)            \n",
    "        #for idx, row in enumerate(row_ind):\n",
    "        #  data[str(t)][\"current\"][idx][\"atq\"] = list(identities)[col_ind[idx]]\n",
    "            \n",
    "        \n",
    "        ##########version with the maximum one feeting \n",
    "        for idx, track in enumerate(data[str(t)][\"current\"]):\n",
    "            track[\"atq\"] = \"None\"\n",
    "            identity_with_max_val= np.argmax(matrice[idx])\n",
    "            #print(identity_with_max_val, list(identities)[identity_with_max_val])\n",
    "            if  L[list(identities)[identity_with_max_val]][\"t=\"+str(t)][idx]>0.2:\n",
    "                data[str(t)][\"current\"][idx][\"atq\"] = list(identities)[identity_with_max_val]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0faba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11f577a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_from_id_and_time(track_id,t):\n",
    "     for idx, track in enumerate(data[str(t)][\"current\"]):\n",
    "            if track[\"track_id\"]==track_id:\n",
    "                return track\n",
    "\"\"\"def get_previous_track_from_id(track_id,t,tmp=1):\n",
    "    while t-tmp>0:\n",
    "        previous_track = get_track_from_id_and_time(track_id,t-tmp)\n",
    "        tmp+=1\n",
    "        if previous_track!=None:\n",
    "            return previous_track\n",
    "    \n",
    "def get_future_track_from_id(track_id,t,tmp=1):\n",
    "    while t+tmp>0:\n",
    "        future_track = get_track_from_id_and_time(track_id,t+tmp)\n",
    "        tmp+=1\n",
    "        if future_track!=None:\n",
    "            return future_track\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "def smooting_from_past(data, gap=750):\n",
    "    for t in V[1:] : \n",
    "         for idx, track in enumerate(data[str(t)][\"current\"]):\n",
    "                if track[\"atq\"]==\"None\":\n",
    "                    track_id=track[\"track_id\"]\n",
    "                    track[\"atq_from_previous\"]=\"None\"\n",
    "                    if t>gap:\n",
    "                        track_previous = get_track_from_id_and_time(track_id,t-1)\n",
    "                        track_far_previous = get_track_from_id_and_time(track_id,t-gap)\n",
    "                        if track_previous!=None and track_far_previous!=None:\n",
    "                            if track_previous[\"atq_from_previous\"]!=\"None\" and track_far_previous[\"atq_from_previous\"]!=\"None\":\n",
    "                                if track_previous[\"atq_from_previous\"]== track_far_previous[\"atq_from_previous\"]:\n",
    "                                    print(t)\n",
    "                                    print(track)\n",
    "                                    data[str(t)][\"current\"][idx][\"atq_from_previous\"]= track_previous[\"atq_from_previous\"]\n",
    "                                    #print(track)\n",
    "                        #except(e):\n",
    "                    #    print(\"an exception occur this is its description:\",e)\n",
    "                else:\n",
    "                    data[str(t)][\"current\"][idx][\"atq_from_previous\"]= track[\"atq\"]\n",
    "\n",
    "\n",
    "def smooting_from_future(data, gap=750):\n",
    "    for t in reversed(V[1:]) : \n",
    "         for idx, track in enumerate(data[str(t)][\"current\"]):\n",
    "                if track[\"atq\"]==\"None\":\n",
    "                    track_id=track[\"track_id\"]\n",
    "                    track[\"atq_from_future\"]=\"None\"\n",
    "                    if V[-1]-t>gap:\n",
    "                        track_future = get_track_from_id_and_time(track_id,t+1)\n",
    "                        track_far_future = get_track_from_id_and_time(track_id,t+gap)\n",
    "\n",
    "                        if track_future!=None and track_far_future!=None:\n",
    "\n",
    "                            if track_future[\"atq_from_future\"]!=\"None\" and track_far_future[\"atq_from_future\"]!=\"None\":\n",
    "\n",
    "                                if track_future[\"atq_from_future\"]== track_far_future[\"atq_from_future\"]:\n",
    "                                    print(t)\n",
    "\n",
    "                                    data[str(t)][\"current\"][idx][\"atq_from_future\"]= track_future[\"atq_from_future\"]\n",
    "                                    print( data[str(t)][\"current\"][idx])\n",
    "                                    #print(track)\n",
    "                        #except(e):\n",
    "                    #    print(\"an exception occur this is its description:\",e)\n",
    "                else:\n",
    "                    data[str(t)][\"current\"][idx][\"atq_from_future\"]= track[\"atq\"]\n",
    "\n",
    "smooting_from_future(data,gap=float('inf')) #=1000)#   4à secondes de gap\n",
    "smooting_from_past(data,gap=float('inf')) # 1000)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781ade7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f928a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############writting on the video#########################\n",
    "\n",
    "  \n",
    "#print(tracks_with_atq)\n",
    "video_path=\"/home/sophie/HMM-Tracking/Bytetrack/videos/GR77_20200512_111314.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)  # float\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "save_path= \"/home/sophie/HMM-Tracking/Bytetrack/videos/GR77_20200512_111314_with_atq24.mp4\"\n",
    "vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (int(width), int(height)))     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Center coordinates\n",
    "center_coordinates = (625, 70)\n",
    " \n",
    "# Radius of circle\n",
    "radius = 2\n",
    "  \n",
    "# Blue color in BGR\n",
    "color = (255, 0, 0)\n",
    "  \n",
    "# Line thickness of 2 px\n",
    "thickness = 2\n",
    "  \n",
    "# Using cv2.circle() method\n",
    "# Draw a circle with blue line borders of thickness of 2 px\n",
    "#frame = cv2.circle(frame, center_coordinates, radius, color, thickness)\n",
    "  \n",
    "  \n",
    "#cv2.imwrite(\"image_.jpg\", frame) \n",
    "\n",
    "print(\"********************** we start writting in the video\")\n",
    "track_file=\"/home/sophie/HMM-Tracking/Bytetrack/videos/GR77_20200512_111314tracking_resut.json\"\n",
    "with open(track_file) as f:\n",
    "        tracks = json.load(f) \n",
    "        \n",
    "\"\"\"print(tracks.keys())    \n",
    "exit(0)    \"\"\"\n",
    "ret_val, frame = cap.read()\n",
    "frame_id=1\n",
    "tracking_result={}\n",
    "while ret_val and frame_id!=V[-1]: \n",
    "    dct={}\n",
    "    ret_val, frame = cap.read()\n",
    "    frame = cv2.circle(frame, center_coordinates, radius, color, thickness)\n",
    "    if str(frame_id) in data.keys():\n",
    "      if (frame!=\"0\" ):\n",
    "        cv2.putText(frame, str(frame_id),(90+580, 20),0, 5e-3 * 200, (0,255,0),2)\n",
    "        for track in data[str(frame_id)][\"current\"]:\n",
    "            track_id=track[\"track_id\"] \n",
    "            tlwh = track[\"location\"]\n",
    "            print(track)\n",
    "            atq= track[\"atq\"] \n",
    "            if atq==\"None\":\n",
    "                if track[\"atq_from_previous\"]!=\"None\":\n",
    "                    atq= track[\"atq_from_previous\"]+'fp'\n",
    "                elif track[\"atq_from_future\"]!=\"None\":\n",
    "                    atq= track[\"atq_from_future\"]+'ff'\n",
    "                    \n",
    "            tid= str(track_id)+\", atq:\"+str(atq)\n",
    "            print(tid)\n",
    "            if atq!=\"None\":\n",
    "                dct[atq]=(int(tlwh[0]), int(tlwh[1]), int(tlwh[2]), int(tlwh[3]) )\n",
    "            cv2.rectangle(frame, (int(tlwh[0]), int(tlwh[1])), (int(tlwh[0])+int(tlwh[2]), int(tlwh[1])+int(tlwh[3])) ,(255,255,255), 2)\n",
    "            cv2.rectangle(frame, (580, 20), (90+580, 115+20) ,(255,255,255), 2)\n",
    "\n",
    "            cv2.putText(frame, str(tid),(int(tlwh[0]), int(tlwh[1])),0, 5e-3 * 200, (0,255,0),2)\n",
    "            \n",
    "        tracking_result[frame_id]=dct\n",
    "        vid_writer.write(frame)\n",
    "    print(\"\\n\", \"\\n\")\n",
    "    frame_id=frame_id+1\n",
    "with open(save_path.split('.mp4')[0]+'tracking_with_HMM_resut.json', 'w') as outfile:\n",
    "    json.dump(tracking_result, outfile)\n",
    "vid_writer.release()\n",
    "#plutôt la surface d'intersection des rectangles plutôt que la distance eucledienne \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa59ddba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
